from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
import os
import csv
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
PROJECT_ROOT = Path(__file__).parent.absolute()
sys.path.append(str(PROJECT_ROOT))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º config –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from tg_bot import config
from tg_bot.table_schema import get_table_schema
from tg_bot.excel_reader import get_cell_value_by_table

llm = ChatOpenAI(
    model="gpt-4o", 
    base_url="https://api.aitunnel.ru/v1/",
    api_key="sk-aitunnel-6dnjLye1zgdGdnSfmM7kuFp3hiPi9qKI",
)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
class TableResponse(BaseModel):
    table_number: str = Field(description="–Ω–æ–º–µ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ç–∞–±–ª–∏—Ü—ã. –ü—Ä–∏–º–µ—Ä: 1.1.1 –∏–ª–∏ 1.1")
    table_name: str = Field(description="–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ç–∞–±–ª–∏—Ü—ã")

class CellResponse(BaseModel):
    column_name: str = Field(description="–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏")
    column_number: int = Field(description="–Ω–æ–º–µ—Ä –∫–æ–ª–æ–Ω–∫–∏")
    row_name: str = Field(description="–Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏")
    row_number: int = Field(description="–Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏")

class CellsResponse(BaseModel):
    cells: List[CellResponse] = Field(description="—Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —è—á–µ–µ–∫")

class CombinedAnalysisResponse(BaseModel):
    result_type: str = Field(description="—Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: both_periods, period_2016_2020, period_2021_2024, tavily_search, not_found")
    cell_info: Dict[str, Any] = Field(description="–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —è—á–µ–π–∫–∞—Ö —Å –ø–æ–ª—è–º–∏ final_selection –∏ all_sources")
    values_by_year: Dict[str, str] = Field(description="–∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≥–æ–¥–∞–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ {–≥–æ–¥: –∑–Ω–∞—á–µ–Ω–∏–µ}")
    analysis_notes: str = Field(description="–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è")

def load_tables_from_csv(file_path=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü –∏–∑ CSV —Ñ–∞–π–ª–∞."""
    if file_path is None:
        file_path = os.path.join(PROJECT_ROOT, '–°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü_21-24.csv')
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü –∏–∑ CSV —Ñ–∞–π–ª–∞."""
    tables = []
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f, delimiter=';')
        for row in reader:
            if len(row) >= 2 and row[1] == '–¢–∞–±–ª–∏—Ü–∞':
                tables.append({"number": row[0], "name": row[0]})
    return tables

def ask_llm_for_table(user_query, tables):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É LLM –Ω–æ–º–µ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ç–∞–±–ª–∏—Ü—ã."""
    tables_text = "\n".join([f"{t['number']}: {t['name']}" for t in tables])
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    parser = JsonOutputParser(pydantic_object=TableResponse)
    
    prompt = PromptTemplate(
        template="""–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
{format_instructions}

–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:
{tables}

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥—Ö–æ–¥—è—Ç —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü—ã, —Ä–∞–∑–¥–µ–ª—ã –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç.""",
        input_variables=["query", "tables"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    
    chain = prompt | llm | parser
    
    try:
        response = chain.invoke({
            "query": user_query,
            "tables": tables_text
        })
        return response["table_number"]
    except Exception:
        return "–ù–ï–¢ –ü–û–î–•–û–î–Ø–©–ï–ô –¢–ê–ë–õ–ò–¶–´"

def ask_llm_for_cells(user_query, schema):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É LLM –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —è—á–µ–π–∫–∞—Ö."""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    parser = JsonOutputParser(pydantic_object=CellsResponse)
    
    prompt = PromptTemplate(
        template="""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã —É–∫–∞–∂–∏ –≤—Å–µ —è—á–µ–π–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
–ï—Å–ª–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —è—á–µ–µ–∫ - –≤–µ—Ä–Ω–∏ –∏—Ö –≤—Å–µ –≤ —Å–ø–∏—Å–∫–µ cells.

{format_instructions}

–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–°—Ö–µ–º–∞ —Ç–∞–±–ª–∏—Ü—ã:
{schema}""",
        input_variables=["query", "schema"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    
    chain = prompt | llm | parser
    
    try:
        response = chain.invoke({
            "query": user_query,
            "schema": schema
        })
        print("\n–û—Ç–≤–µ—Ç LLM:")
        print(json.dumps(response, ensure_ascii=False, indent=2))
        return json.dumps(response, ensure_ascii=False)
    except Exception as e:
        print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM: {str(e)}")
        return "–ù–ï –£–î–ê–õ–û–°–¨ –ù–ê–ô–¢–ò –ù–£–ñ–ù–´–ï –Ø–ß–ï–ô–ö–ò –í –¢–ê–ë–õ–ò–¶–ï"

def analyze_combined_results(
    user_query: str,
    result_2124: Dict[str, Any],
    result_1620: Dict[str, Any],
    tavily_result: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –¥–≤—É—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏ Tavily –ø–æ–∏—Å–∫–∞ —Å –ø–æ–º–æ—â—å—é LLM.
    
    Args:
        user_query (str): –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result_2124 (Dict[str, Any]): –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ 2021-2024
        result_1620 (Dict[str, Any]): –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ 2016-2020
        tavily_result (Dict[str, Any], optional): –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ Tavily
        
    Returns:
        Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ LLM
    """
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    parser = JsonOutputParser(pydantic_object=CombinedAnalysisResponse)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    period_2124_info = "–ù–ï–¢ –î–ê–ù–ù–´–•"
    period_1620_info = "–ù–ï–¢ –î–ê–ù–ù–´–•"
    tavily_info = "–ù–ï–¢ –î–ê–ù–ù–´–•"
    
    if result_2124["success"]:
        data_2124 = result_2124["data"]
        cells_info_2124 = []
        for cell in data_2124["cells_data"]:
            cells_info_2124.append(f"–ö–æ–ª–æ–Ω–∫–∞: {cell['column_name']}, –°—Ç—Ä–æ–∫–∞: {cell['row_name']}, –ó–Ω–∞—á–µ–Ω–∏—è: {cell['values']}")
        
        period_2124_info = f"""
–¢–∞–±–ª–∏—Ü–∞: {data_2124['table_number']} - {data_2124['table_name']}
–ù–∞–π–¥–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏:
{chr(10).join(cells_info_2124)}"""
    else:
        period_2124_info = f"–û–®–ò–ë–ö–ò: {'; '.join(result_2124['errors'])}"
    
    if result_1620["success"]:
        data_1620 = result_1620["data"]
        cells_info_1620 = []
        for cell in data_1620["cells_data"]:
            cells_info_1620.append(f"–ö–æ–ª–æ–Ω–∫–∞: {cell['column_name']}, –°—Ç—Ä–æ–∫–∞: {cell['row_name']}, –ó–Ω–∞—á–µ–Ω–∏—è: {cell['values']}")
        
        period_1620_info = f"""
–¢–∞–±–ª–∏—Ü–∞: {data_1620['table_number']} - {data_1620['table_name']}
–ù–∞–π–¥–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏:
{chr(10).join(cells_info_1620)}"""
    else:
        period_1620_info = f"–û–®–ò–ë–ö–ò: {'; '.join(result_1620['errors'])}"
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö Tavily, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if tavily_result and tavily_result.get("success"):
        data_tavily = tavily_result["data"]
        cells_info_tavily = []
        for cell in data_tavily["cells_data"]:
            cells_info_tavily.append(f"–ö–æ–ª–æ–Ω–∫–∞: {cell['column_name']}, –°—Ç—Ä–æ–∫–∞: {cell['row_name']}, –ó–Ω–∞—á–µ–Ω–∏—è: {cell['values']}")
        
        tavily_info = f"""
–ò—Å—Ç–æ—á–Ω–∏–∫: {data_tavily['table_number']} - {data_tavily['table_name']}
–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {data_tavily.get('data_quality', 'unknown')}
–ê–Ω–∞–ª–∏–∑: {data_tavily.get('analysis_summary', '–ù–µ—Ç –∞–Ω–∞–ª–∏–∑–∞')}
–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
{chr(10).join(cells_info_tavily)}"""
    elif tavily_result and not tavily_result.get("success"):
        tavily_info = f"–û–®–ò–ë–ö–ò TAVILY: {'; '.join(tavily_result.get('errors', ['–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞']))}"
    
    prompt = PromptTemplate(
        template="""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –¥–≤–∞ –ø–µ—Ä–∏–æ–¥–∞ –∏ –¥–∞–Ω–Ω—ã–µ Tavily –ø–æ–∏—Å–∫–∞, –ø—Ä–∏–º–∏ —Ä–µ—à–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫ –ª—É—á—à–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

{format_instructions}

–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –ø–µ—Ä–∏–æ–¥ 2021-2024:
{period_2124}

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –ø–µ—Ä–∏–æ–¥ 2016-2020:
{period_1620}

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ Tavily:
{tavily_data}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û—Ü–µ–Ω–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
2. –ü—Ä–∏–Ω—è—Ç—å –æ–¥–Ω–æ –∏–∑ —Ä–µ—à–µ–Ω–∏–π:
   - "both_periods": –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±–æ–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ/—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ - –æ–±—ä–µ–¥–∏–Ω–∏ –∏—Ö –≤ –æ–¥–Ω—É —Å–µ—Ä–∏—é 2016-2024
   - "period_2021_2024": –µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ 2021-2024
   - "period_2016_2020": –µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ 2016-2020
   - "tavily_search": –µ—Å–ª–∏ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ Tavily –ø–æ–∏—Å–∫–∞
   - "not_found": –µ—Å–ª–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –∏–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

3. –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —è—á–µ–µ–∫, –≤—ã–±–µ—Ä–∏ –æ–¥–Ω—É –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞
4. –í cell_info.final_selection —É–∫–∞–∂–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —è—á–µ–π–∫–∏, –≤ cell_info.all_sources - –≤—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
5. –í values_by_year –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∏—Ç–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞/–∏—Å—Ç–æ—á–Ω–∏–∫–∞
6. –í analysis_notes –æ–±—ä—è—Å–Ω–∏ —Å–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∏ —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö""",
        input_variables=["query", "period_2124", "period_1620", "tavily_data"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    
    chain = prompt | llm | parser
    
    try:
        response = chain.invoke({
            "query": user_query,
            "period_2124": period_2124_info,
            "period_1620": period_1620_info,
            "tavily_data": tavily_info
        })
        print("\n–û—Ç–≤–µ—Ç LLM –∞–Ω–∞–ª–∏–∑–∞:")
        print(json.dumps(response, ensure_ascii=False, indent=2))
        return response
    except Exception as e:
        print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")
        return {
            "result_type": "not_found",
            "cell_info": {"final_selection": [], "all_sources": []},
            "values_by_year": {},
            "analysis_notes": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
        }


def format_terminal_output(table_number: str, table_name: str, cells_data: List[Dict]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª.
    
    Args:
        table_number (str): –ù–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã
        table_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        cells_data (List[Dict]): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —è—á–µ–µ–∫
        
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞
    """
    output = [f"–¢–∞–±–ª–∏—Ü–∞ {table_number}: {table_name}\n"]
    output.append("\n–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\n")
    
    for cell_data in cells_data:
        output.append(f"–ö–æ–ª–æ–Ω–∫–∞: {cell_data['column_name']}")
        output.append(f"–°—Ç—Ä–æ–∫–∞: {cell_data['row_name']}")
        for year, value in cell_data['values'].items():
            output.append(f"{year}: {value}")
        output.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —è—á–µ–π–∫–∞–º–∏
    
    return "\n".join(output)

def format_combined_analysis_output(analysis_result: Dict[str, Any]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª.
    
    Args:
        analysis_result (Dict[str, Any]): –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ LLM
        
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞
    """
    output = ["\n" + "="*60]
    output.append("–ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó")
    output.append("="*60)
    
    result_type = analysis_result.get("result_type", "not_found")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    type_descriptions = {
        "both_periods": "–î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –∏–∑ –æ–±–æ–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ (2016-2024)",
        "period_2021_2024": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –∑–∞ –ø–µ—Ä–∏–æ–¥ 2021-2024",
        "period_2016_2020": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –∑–∞ –ø–µ—Ä–∏–æ–¥ 2016-2020",
        "tavily_search": "–î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫ (Tavily)",
        "not_found": "–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    }
    
    output.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {type_descriptions.get(result_type, result_type)}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —è—á–µ–π–∫–∞—Ö
    cell_info = analysis_result.get("cell_info", {})
    final_selection = cell_info.get("final_selection", [])
    
    if final_selection:
        output.append("\n–í—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        for cell in final_selection:
            if isinstance(cell, dict):
                column = cell.get("column_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                row = cell.get("row_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                output.append(f"  –ö–æ–ª–æ–Ω–∫–∞: {column}")
                output.append(f"  –°—Ç—Ä–æ–∫–∞: {row}")
    
    # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ –≥–æ–¥–∞–º
    values_by_year = analysis_result.get("values_by_year", {})
    if values_by_year:
        output.append("\n–ó–Ω–∞—á–µ–Ω–∏—è –ø–æ –≥–æ–¥–∞–º:")
        for year in sorted(values_by_year.keys()):
            output.append(f"  {year}: {values_by_year[year]}")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Tavily
    if result_type == "tavily_search":
        output.append("\nüì° –ò–°–¢–û–ß–ù–ò–ö: –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Tavily API")
        output.append("‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")
        output.append("üîç –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    
    # –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
    analysis_notes = analysis_result.get("analysis_notes", "")
    if analysis_notes:
        output.append(f"\n–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {analysis_notes}")
    
    return "\n".join(output)

def process_cell_values(
    table_number: str, 
    cells_response: str,
    start_year: str,
    end_year: str
) -> List[Dict]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç LLM –∏ –ø–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è —è—á–µ–µ–∫.
    
    Args:
        table_number (str): –ù–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã
        cells_response (str): JSON-–æ—Ç–≤–µ—Ç –æ—Ç LLM —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —è—á–µ–π–∫–∞—Ö
        start_year (str): –ì–æ–¥ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞
        end_year (str): –ì–æ–¥ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —è—á–µ–µ–∫
    """
    cells_data = []
    response_data = json.loads(cells_response)
    
    for cell_info in response_data['cells']:
        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —è—á–µ–π–∫–∏
        values = get_cell_value_by_table(
            table_number,
            cell_info['column_number'],
            cell_info['row_number'],
            start_year,
            end_year
        )
        
        cells_data.append({
            'column_name': cell_info['column_name'],
            'row_name': cell_info['row_name'],
            'values': values
        })
    
    return cells_data

def process_query(
    tables_csv_path: str,
    start_year: str,
    end_year: str,
    user_query: str
) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    
    Args:
        tables_csv_path (str): –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å–æ —Å–ø–∏—Å–∫–æ–º —Ç–∞–±–ª–∏—Ü
        start_year (str): –ì–æ–¥ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞
        end_year (str): –ì–æ–¥ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞
        user_query (str): –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
    Returns:
        Dict[str, Any]: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
    """
    errors = []
    result = {
        "success": False,
        "errors": errors,
        "data": None
    }
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü
        tables = load_tables_from_csv(tables_csv_path)
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ç–∞–±–ª–∏—Ü—ã
        table_number = ask_llm_for_table(user_query, tables)
        
        if table_number == "–ù–ï–¢ –ü–û–î–•–û–î–Ø–©–ï–ô –¢–ê–ë–õ–ò–¶–´":
            errors.append("–≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã - –ù–ï–¢ –ü–û–î–•–û–î–Ø–©–ï–ô –¢–ê–ë–õ–ò–¶–´")
            return result
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        table_name = next((t['name'] for t in tables if t['number'] == table_number), '')
            
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã
        schema = get_table_schema(table_number, year=end_year)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —è—á–µ–π–∫–∞—Ö
        cells_response = ask_llm_for_cells(user_query, schema)
        
        if cells_response == "–ù–ï –£–î–ê–õ–û–°–¨ –ù–ê–ô–¢–ò –ù–£–ñ–ù–´–ï –Ø–ß–ï–ô–ö–ò –í –¢–ê–ë–õ–ò–¶–ï":
            errors.append(f"–≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã - –ù–ê–ô–î–ï–ù–ê –¢–ê–ë–õ–ò–¶–ê {table_number}")
            errors.append("–≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —è—á–µ–µ–∫ - –ù–ï –£–î–ê–õ–û–°–¨ –ù–ê–ô–¢–ò –ù–£–ñ–ù–´–ï –Ø–ß–ï–ô–ö–ò –í –¢–ê–ë–õ–ò–¶–ï")
            return result
            
        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —è—á–µ–µ–∫
        cells_data = process_cell_values(table_number, cells_response, start_year, end_year)
        
        result["success"] = True
        result["data"] = {
            "table_number": table_number,
            "table_name": table_name,
            "cells_data": cells_data
        }
        
    except Exception as e:
        errors.append(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
    
    result["errors"] = errors
    return result

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    user_query = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å: ")
    
    # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2021-2024
    print("\n" + "="*60)
    print("–ü–ï–†–ò–û–î 2021-2024")
    print("="*60)
    
    tables_csv_path_2124 = os.path.join(PROJECT_ROOT, '–°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü_21-24.csv')
    result_2124 = process_query(
        tables_csv_path=tables_csv_path_2124,
        start_year="2021",
        end_year="2024",
        user_query=user_query
    )
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2021-2024
    if result_2124["success"]:
        print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2021-2024:")
        print(format_terminal_output(
            result_2124["data"]["table_number"],
            result_2124["data"]["table_name"],
            result_2124["data"]["cells_data"]
        ))
    else:
        print("\n–û—à–∏–±–∫–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2021-2024:")
        for error in result_2124["errors"]:
            print(error)
    
    # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2016-2020
    print("\n" + "="*60)
    print("–ü–ï–†–ò–û–î 2016-2020")
    print("="*60)
    
    tables_csv_path_1620 = os.path.join(PROJECT_ROOT, '–°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü_16-20.csv')
    result_1620 = process_query(
        tables_csv_path=tables_csv_path_1620,
        start_year="2016",
        end_year="2020",
        user_query=user_query
    )
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2016-2020
    if result_1620["success"]:
        print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2016-2020:")
        print(format_terminal_output(
            result_1620["data"]["table_number"],
            result_1620["data"]["table_name"],
            result_1620["data"]["cells_data"]
        ))
    else:
        print("\n–û—à–∏–±–∫–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ 2016-2020:")
        for error in result_1620["errors"]:
            print(error)
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "="*60)
    print("–ê–ù–ê–õ–ò–ó –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*60)
    
    combined_analysis = analyze_combined_results(user_query, result_2124, result_1620)
    print(format_combined_analysis_output(combined_analysis))

if __name__ == "__main__":
    main()
